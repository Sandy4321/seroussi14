'''
Created on Sep 14, 2015

@author: thomas
'''
import string


class Corpus(object):
    '''
    Class to store a text corpus.
    '''
    
    def __init__(self,name):
        '''
        Constructor
        '''
        self.documents = []
        self.name = name
        
        # Initialize corpus variables.
        self.V = 0      # Number of words in vocabulary.
        self.D = 0      # Number of documents.
        self.A = 0      # Number of authors.
        self.authors = {}
        self.is_stopword = []   # List of stopword identifier. 0 if not, 1 if its a stopword.
        self.num_stopwords = 0  # Counter for the number of stopwords in the vocabulary.
        
        
    def index_douments(self):
        '''
        Apply an integer index to documents for use in model.
        '''
        # Loop over all document and assign the index according to the corpus' document list.
        for index, doc in enumerate(self.documents):
            doc.index = index
        
        
    def separate_words(self):
        '''
        For every document built a list of words_strings out of the documents' text.
        '''
        for doc in self.documents:
            doc.separate_words()
            
            
    def built_vocabluary(self):
        '''
        Built a list of words_strings in the corpus.
        The separate_words functions must be called prior to this function.
        '''
        # Create an empty set.
        vocab_set = set()
        
        # Loop over documents.
        for doc in self.documents:
            # Loop over words_strings and add each word to the set.
            for word in doc.words_strings:
                vocab_set.add(word)
        # Update vocabulary size variable.
        self.V = len(vocab_set)
        # Store the vocabulary in a dict.
        self.vocab_dict = dict(zip(vocab_set,range(self.V)))
        # Store the vocabulary in a list with indices according to their values in the dict.
        self.vocab = [None]*self.V
        for word in self.vocab_dict.keys():
            self.vocab[self.vocab_dict[word]] = word
        
        
    def index_words(self):
        '''
        Apply the integer index for every word according to the vocabulary dict.
        '''
        
        # Loop over all documents.
        for doc in self.documents:
            # Loop over all words in a document.
            for word in doc.words_strings:
                doc.words.append(self.vocab_dict[word])
      
      
    def find_all_authors(self):
        '''
        Construct a dict containing author IDs as keys and integer indices.
        '''
        # Initialize a set.
        authorID_set = set()
        # Loop over all documents and add the author to the set.
        for doc in self.documents:
            authorID_set.add(doc.authorID)
        # Update the number of authors.
        self.A = len(authorID_set)
        # Construct the dict containing IDs as keys and integer indices.
        self.authors = dict(zip(authorID_set,range(self.A)))
      
    def index_authors(self):
        '''
        Store the index of every documents author in the document object.
        '''
        # Loop over all documents.
        for doc in self.documents:
            doc.author_index = self.authors[doc.authorID]
            
    
    def identify_stopwords(self):
        '''
        Identify whether a word is a stop word according to a given list of stopwords.
        '''
        # Stop Word List 2
        # http://www.lextek.com/manuals/onix/stopwords2.html
        # This stopword list was built by Gerard Salton and Chris Buckley for the experimental SMART information retrieval system at Cornell University. This stopword list is generally considered to be on the larger side and so when it is used, some implementations edit it so that it is better suited for a given domain and audience while others use this stopword list as it stands. This wordlist is 571 words in length.
        # Freely available stopword list generated by 
        # Chris Buckley and Gerard Salton at Cornell University.
        stop_words = {"a","a's","able","about","above","according","accordingly","across","actually","after","afterwards","again","against","ain't","all","allow","allows","almost","alone","along","already","also","although","always","am","among","amongst","an","and","another","any","anybody","anyhow","anyone","anything","anyway","anyways","anywhere","apart","appear","appreciate","appropriate","are","aren't","around","as","aside","ask","asking","associated","at","available","away","awfully","b","be","became","because","become","becomes","becoming","been","before","beforehand","behind","being","believe","below","beside","besides","best","better","between","beyond","both","brief","but","by","c","c'mon","c's","came","can","can't","cannot","cant","cause","causes","certain","certainly","changes","clearly","co","com","come","comes","concerning","consequently","consider","considering","contain","containing","contains","corresponding","could","couldn't","course","currently","d","definitely","described","despite","did","didn't","different","do","does","doesn't","doing","don't","done","down","downwards","during","e","each","edu","eg","eight","either","else","elsewhere","enough","entirely","especially","et","etc","even","ever","every","everybody","everyone","everything","everywhere","ex","exactly","example","except","f","far","few","fifth","first","five","followed","following","follows","for","former","formerly","forth","four","from","further","furthermore","g","get","gets","getting","given","gives","go","goes","going","gone","got","gotten","greetings","h","had","hadn't","happens","hardly","has","hasn't","have","haven't","having","he","he's","hello","help","hence","her","here","here's","hereafter","hereby","herein","hereupon","hers","herself","hi","him","himself","his","hither","hopefully","how","howbeit","however","i","i'd","i'll","i'm","i've","ie","if","ignored","immediate","in","inasmuch","inc","indeed","indicate","indicated","indicates","inner","insofar","instead","into","inward","is","isn't","it","it'd","it'll","it's","its","itself","j","just","k","keep","keeps","kept","know","knows","known","l","last","lately","later","latter","latterly","least","less","lest","let","let's","like","liked","likely","little","look","looking","looks","ltd","m","mainly","many","may","maybe","me","mean","meanwhile","merely","might","more","moreover","most","mostly","much","must","my","myself","n","name","namely","nd","near","nearly","necessary","need","needs","neither","never","nevertheless","new","next","nine","no","nobody","non","none","noone","nor","normally","not","nothing","novel","now","nowhere","o","obviously","of","off","often","oh","ok","okay","old","on","once","one","ones","only","onto","or","other","others","otherwise","ought","our","ours","ourselves","out","outside","over","overall","own","p","particular","particularly","per","perhaps","placed","please","plus","possible","presumably","probably","provides","q","que","quite","qv","r","rather","rd","re","really","reasonably","regarding","regardless","regards","relatively","respectively","right","s","said","same","saw","say","saying","says","second","secondly","see","seeing","seem","seemed","seeming","seems","seen","self","selves","sensible","sent","serious","seriously","seven","several","shall","she","should","shouldn't","since","six","so","some","somebody","somehow","someone","something","sometime","sometimes","somewhat","somewhere","soon","sorry","specified","specify","specifying","still","sub","such","sup","sure","t","t's","take","taken","tell","tends","th","than","thank","thanks","thanx","that","that's","thats","the","their","theirs","them","themselves","then","thence","there","there's","thereafter","thereby","therefore","therein","theres","thereupon","these","they","they'd","they'll","they're","they've","think","third","this","thorough","thoroughly","those","though","three","through","throughout","thru","thus","to","together","too","took","toward","towards","tried","tries","truly","try","trying","twice","two","u","un","under","unfortunately","unless","unlikely","until","unto","up","upon","us","use","used","useful","uses","using","usually","uucp","v","value","various","very","via","viz","vs","w","want","wants","was","wasn't","way","we","we'd","we'll","we're","we've","welcome","well","went","were","weren't","what","what's","whatever","when","whence","whenever","where","where's","whereafter","whereas","whereby","wherein","whereupon","wherever","whether","which","while","whither","who","who's","whoever","whole","whom","whose","why","will","willing","wish","with","within","without","won't","wonder","would","would","wouldn't","x","y","yes","yet","you","you'd","you'll","you're","you've","your","yours","yourself","yourselves","z","zero"}
        
        # Loop over all words.
        for word in self.vocab:
            if word in stop_words:
                self.is_stopword.append(1)
                # Update counter.
                self.num_stopwords += 1
            else:
                self.is_stopword.append(0)
      
      
    def process_raw_data(self):
        '''
        Apply all the steps necessary to obtain data in the form needed for the algorithm.
        '''
        # Word processing.
        self.separate_words()
        self.built_vocabluary()
        self.index_words()
        self.identify_stopwords()
        # Author processing.
        self.find_all_authors()
        self.index_authors()
        
        
    def print_status(self):
        '''
        Print some information about the corpus.
        '''
        print("Vocabulary size : {}".format(self.V))
        print("Number of documents : {}".format(self.D)) 
        print("Number of authors : {}".format(self.A))
        print("Number of stopwords : {} of 571 in stopword list.".format(self.num_stopwords))

                
        
class Document:
    '''
    Class to store and process document data
    '''
    
    # Set with punctuation characters.
    punct = set(string.punctuation)
    
    def __init__(self, ID):
        self.body = ""
        self.ID = ID
        self.index = 0  # Integer index for use in the model.
        self.authorID = ""
        self.author_index = -1    # Variable for the author index according to the set of corpus authors.
        # Initialize list for words in form of a string.
        self.words_strings = []
        # Initialize list for words in form of an index.
        self.words = []
        # Number of words in the document.
        self.N = 0
        
        
    def separate_words(self):
        ''' 
        Construct a list with words using the text in self.body.
        Words are not necessarily in the original sequence.
        Punctuation at the beginning and the end gets removed.
        '''
        
        words_splitted = string.split(self.body)
        
        # Loop over words.
        for word in words_splitted:
            # Ignore names specified by <NAME/>, for PAN11.
            word = word.replace("<NAME/>","")
            
            # Make all characters lower case.
            word = string.lower(word)
            
            # Set flags to false.
            is_left_punctuation_removed = False
            is_right_punctuation_removed = False
            
            # Loop until flags is True.
            while not(is_left_punctuation_removed and is_right_punctuation_removed):
                # Check beginning for punctuation character.
                if len(word) > 0 and word[0] in self.punct:
                    self.words_strings.append(word[0])
                    if len(word) > 0:
                        word = word[1:]
                else:
                    is_left_punctuation_removed = True
                # Check end for punctuation character.
                if len(word) > 0 and word[-1] in self.punct:
                    self.words_strings.append(word[-1])
                    if len(word) > 0:
                        word = word[:-1]
                else:
                    is_right_punctuation_removed = True
                    
            if len(word) > 0:
                self.words_strings.append(word)
        
        # Update number of words.
        self.N = len(self.words_strings)
                        